# =============================================================================
# Eclaire Configuration
# =============================================================================
#
# This file works for both self-hosted (Docker) and local development setups.
# Wiring details (hostnames, ports) are derived automatically from ECLAIRE_RUNTIME.
#
# Setup:
#   Self-hosted:  ./setup.sh  (or curl setup from releases)
#   Development:  pnpm setup:dev
#
# Both commands generate secrets and prepare this file for use.
# =============================================================================

# -----------------------------------------------------------------------------
# Security Secrets (REQUIRED - generated by setup scripts)
# -----------------------------------------------------------------------------
# Generate manually with: openssl rand -hex 32
BETTER_AUTH_SECRET=
MASTER_ENCRYPTION_KEY=
API_KEY_HMAC_KEY_V1=

# -----------------------------------------------------------------------------
# Database Configuration
# -----------------------------------------------------------------------------
# Default: postgres (recommended for dev/prod parity)
# Options: sqlite | pglite | postgres
DATABASE_TYPE=postgres

# Queue backend (set by setup script to match database type)
# Options: sqlite | postgres | redis
# Note: sqlite queue requires SERVICE_ROLE=all and DATABASE_TYPE=sqlite
QUEUE_BACKEND=postgres

# PostgreSQL connection (optional - defaults work with included postgres container)
# Host auto-detected: 'postgres' in containers, '127.0.0.1' locally
#DATABASE_HOST=
#DATABASE_PORT=5432
#DATABASE_USER=eclaire
#DATABASE_PASSWORD=eclaire
#DATABASE_NAME=eclaire

# Or provide a full connection string (overrides individual settings)
#DATABASE_URL=

# SQLite/PGlite data directories (only if using sqlite/pglite)
#SQLITE_DATA_DIR=./data/sqlite
#PGLITE_DATA_DIR=./data/pglite

# -----------------------------------------------------------------------------
# Service Mode
# -----------------------------------------------------------------------------
# Default: all (unified mode - API + workers in single process)
# Options: all | api | worker
#SERVICE_ROLE=all

# -----------------------------------------------------------------------------
# Server
# -----------------------------------------------------------------------------
# Port auto-detected: 3000 in containers, 3001 locally
#PORT=

# Public-facing URL (for OAuth callbacks, email links, etc.)
#FRONTEND_URL=http://localhost:3000

# -----------------------------------------------------------------------------
# AI Configuration
# -----------------------------------------------------------------------------
# Providers and models are configured in config/ai/*.json
# Setup scripts copy example configs automatically.
#
# Local LLM server URLs are auto-detected based on ECLAIRE_RUNTIME:
#   - Container: http://host.docker.internal:<port>/v1
#   - Local:     http://127.0.0.1:<port>/v1
#
# Override only if your setup differs from defaults:
#LLAMA_CPP_BASE_URL=http://127.0.0.1:11500/v1
#LLAMA_CPP_BASE_URL_2=http://127.0.0.1:11501/v1
#OLLAMA_BASE_URL=http://127.0.0.1:11434/v1
#LM_STUDIO_BASE_URL=http://127.0.0.1:1234/v1
#MLX_LM_BASE_URL=http://127.0.0.1:8080/v1
#MLX_VLM_BASE_URL=http://127.0.0.1:8080/v1

# Cloud provider API keys (referenced by config/ai/providers.json)
#OPENAI_API_KEY=sk-...
#ANTHROPIC_API_KEY=sk-ant-...
#OPENROUTER_API_KEY=sk-or-...

# -----------------------------------------------------------------------------
# External Services
# -----------------------------------------------------------------------------
# Docling URL auto-detected: 'http://docling:5001' in containers, 'http://127.0.0.1:5001' locally
# Override only if your setup differs:
#DOCLING_SERVER_URL=

# GitHub token (for higher rate limits on GitHub bookmark processing)
#GITHUB_TOKEN=

# Reddit API (for Reddit bookmark processing)
#REDDIT_CLIENT_ID=
#REDDIT_CLIENT_SECRET=

# -----------------------------------------------------------------------------
# Performance Tuning (optional)
# -----------------------------------------------------------------------------
#LOG_LEVEL=info
#WORKER_CONCURRENCY=5
#AI_TIMEOUT=180000
