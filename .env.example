# =============================================================================
# Eclaire Configuration (Docker)
# =============================================================================
# 1. Copy to .env:    cp .env.example .env
# 2. Generate secrets: for i in {1..5}; do openssl rand -hex 32; done
# 3. Start LLM:       ollama serve
# 4. Start app:       docker compose up -d
# =============================================================================

# -----------------------------------------------------------------------------
# Security Secrets (REQUIRED - generate with: openssl rand -hex 32)
# -----------------------------------------------------------------------------
BETTER_AUTH_SECRET=
MASTER_ENCRYPTION_KEY=
API_KEY_HMAC_KEY_V1=
WORKER_API_KEY=
AI_ASSISTANT_API_KEY=

# -----------------------------------------------------------------------------
# Database Configuration
# -----------------------------------------------------------------------------
# Default: sqlite (simplest, no external database needed)
# Options: sqlite | pglite | postgresql
#DATABASE_TYPE=sqlite

# SQLite/PGlite data directories (optional, defaults work for most setups)
#SQLITE_DATA_DIR=./data/sqlite
#PGLITE_DATA_DIR=./data/pglite

# PostgreSQL settings (only needed if DATABASE_TYPE=postgresql)
# Use: docker compose --profile postgres up
#DATABASE_HOST=postgres
#DATABASE_PORT=5432
#DATABASE_USER=eclaire
#DATABASE_PASSWORD=eclaire
#DATABASE_NAME=eclaire

# Or provide a full connection string (overrides individual settings above)
#DATABASE_URL=postgresql://eclaire:eclaire@postgres:5432/eclaire

# -----------------------------------------------------------------------------
# Queue Configuration
# -----------------------------------------------------------------------------
# Default: sqlite (in-process queue, simplest setup)
# Options: sqlite | postgres | redis
#
# Note: sqlite queue requires SERVICE_ROLE=all (single process mode)
# For distributed workers, use postgres or redis queue
#QUEUE_BACKEND=sqlite

# Redis settings (only needed if QUEUE_BACKEND=redis)
# Use: docker compose --profile redis up
#REDIS_URL=redis://redis:6379
#REDIS_KEY_PREFIX=eclaire

# -----------------------------------------------------------------------------
# Service Mode
# -----------------------------------------------------------------------------
# Default: all (unified mode - API + workers in single process)
# Options: all | api | worker
#
# - all: Run everything in one process (recommended for simple deployments)
# - api: Run only the HTTP API (workers run separately)
# - worker: Run only queue workers (API runs separately)
#SERVICE_ROLE=all

# -----------------------------------------------------------------------------
# Server
# -----------------------------------------------------------------------------
# Port the app listens on (also used for host port mapping in compose)
#PORT=3000

# -----------------------------------------------------------------------------
# URLs
# -----------------------------------------------------------------------------
# Your public-facing URL (for OAuth callbacks, email links, etc.)
#FRONTEND_URL=http://localhost:3000

# -----------------------------------------------------------------------------
# AI Provider
# -----------------------------------------------------------------------------
# Default: http://host.docker.internal:11434 (Ollama running on host)
# The container connects to your host machine via Docker's special hostname.
#
# Backend AI (for user-facing AI features)
#AI_LOCAL_PROVIDER_URL=http://host.docker.internal:11434
#
# Worker AI (for background processing - can be same or different server)
#WORKER_AI_LOCAL_PROVIDER_URL=http://host.docker.internal:11435

# Optional: Proxy provider (OpenRouter, OpenAI, etc.)
#AI_PROXY_PROVIDER_URL=https://openrouter.ai/api/v1/chat/completions
#AI_PROXY_API_KEY=

# Worker-specific proxy (if workers need different proxy than backend)
#WORKER_AI_PROXY_PROVIDER_URL=https://openrouter.ai/api/v1/chat/completions
#WORKER_AI_PROXY_API_KEY=

# -----------------------------------------------------------------------------
# External Services
# -----------------------------------------------------------------------------
# Docling document processing server (runs in compose, no config needed)
# Default: http://docling:5001

# GitHub token (for higher rate limits on GitHub bookmark processing)
#GITHUB_TOKEN=

# Reddit API (for Reddit bookmark processing)
#REDDIT_CLIENT_ID=
#REDDIT_CLIENT_SECRET=

# -----------------------------------------------------------------------------
# OPTIONAL: Performance Tuning
# -----------------------------------------------------------------------------
#LOG_LEVEL=info
#WORKER_CONCURRENCY=5
#AI_TIMEOUT=180000
